{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Langchain Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify path for pdfs and chroma database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "CHROMA_PATH = \"chroma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pdf(s) with the help of PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "___________________________________________\n",
      "FORM 10-K \n",
      "___________________________________________\n",
      "(Mark One)\n",
      "‚òí ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the fiscal year ended December 31, 2023 \n",
      "OR\n",
      "‚òê TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the transition period from              to             .\n",
      "Commission file number: 001-37580 \n",
      "___________________________________________\n",
      "Alphabet Inc. \n",
      "(Exact name of registrant as specified in its charter)\n",
      "___________________________________________\n",
      "Delaware 61-1767919\n",
      "(State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification No.)\n",
      "1600 Amphitheatre Parkway \n",
      "Mountain View, CA 94043 \n",
      "(Address of principal executive offices, including zip code)\n",
      "(650) 253-0000 \n",
      "(Registrant's telephone number, including area code)\n",
      "Securities registered pursuant to Section 12(b) of the Act:\n",
      "Title of each class Trading Symbol(s) Name of each exchange on which registered\n",
      "Class A Common Stock, $0.001 par value GOOGL Nasdaq Stock Market LLC\n",
      "(Nasdaq Global Select Market)\n",
      "Class C Capital Stock, $0.001 par value GOOG Nasdaq Stock Market LLC\n",
      "(Nasdaq Global Select Market)\n",
      "Securities registered pursuant to Section 12(g) of the Act:\n",
      "Title of each class\n",
      "None\n",
      "___________________________________________\n",
      "Indicate by check mark if the registrant is a well-known seasoned issuer, as defined in Rule 405 of the Securities \n",
      "Act.    Yes  ‚òí    No  ‚òê\n",
      "Indicate by check mark if the registrant is not required to file reports pursuant to Section 13 or Section 15(d) of the \n",
      "Act.    Yes  ‚òê   No  ‚òí\n",
      "Indicate by check mark whether the registrant (1) has filed all reports required to be filed by Section 13 or 15(d) of the Securities \n",
      "Exchange Act of 1934 during the preceding 12 months (or for such shorter period that the registrant was required to file such \n",
      "reports), and (2) has been subject to such filing requirements for the past 90 days.    Yes  ‚òí    No  ‚òê\n",
      "Indicate by check mark whether the registrant has submitted electronically every Interactive Data File required to be submitted \n",
      "pursuant to Rule 405 of Regulation S-T (¬ß232.405 of this chapter) during the preceding 12 months (or for such shorter period that \n",
      "the registrant was required to submit such files).    Yes  ‚òí    No  ‚òê\n",
      "Indicate by check mark whether the registrant is a large accelerated filer, an accelerated filer, a non-accelerated filer, a smaller \n",
      "reporting company, or an emerging growth company. See the definitions of ‚Äúlarge accelerated filer,‚Äù ‚Äúaccelerated filer,‚Äù ‚Äúsmaller \n",
      "reporting company,‚Äù and \"emerging growth company\" in Rule 12b-2 of the Exchange Act.' metadata={'source': 'data\\\\goog-10-k-2023 (1).pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "def load_documents():\n",
    "    document_loader= PyPDFDirectoryLoader(DATA_PATH)\n",
    "    return document_loader.load()\n",
    "\n",
    "documents = load_documents()\n",
    "print(documents[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the document is created, split the texts into number of chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='UNITED STATES\n",
      "SECURITIES AND EXCHANGE COMMISSION\n",
      "Washington, D.C. 20549\n",
      "___________________________________________\n",
      "FORM 10-K \n",
      "___________________________________________\n",
      "(Mark One)\n",
      "‚òí ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the fiscal year ended December 31, 2023 \n",
      "OR\n",
      "‚òê TRANSITION REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934\n",
      "For the transition period from              to             .\n",
      "Commission file number: 001-37580 \n",
      "___________________________________________\n",
      "Alphabet Inc. \n",
      "(Exact name of registrant as specified in its charter)\n",
      "___________________________________________\n",
      "Delaware 61-1767919\n",
      "(State or other jurisdiction of incorporation or organization) (I.R.S. Employer Identification No.)\n",
      "1600 Amphitheatre Parkway \n",
      "Mountain View, CA 94043 \n",
      "(Address of principal executive offices, including zip code)\n",
      "(650) 253-0000 \n",
      "(Registrant's telephone number, including area code)' metadata={'source': 'data\\\\goog-10-k-2023 (1).pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=100,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "documents = load_documents()\n",
    "chunks = split_documents(documents)\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the chunks are created, establish embedding for them to inculcate into database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "class TextEmbedder:\n",
    "    def __init__(self, model_name=\"nomic-embed-text\"):\n",
    "        self.embeddings = OllamaEmbeddings(model=model_name)\n",
    "    \n",
    "    def embed_query(self, query):\n",
    "        # Assuming OllamaEmbeddings has an embed method, you can call it here\n",
    "        return self.embeddings.embed(query)\n",
    "\n",
    "# Now use this class in your Chroma setup\n",
    "embedding_function = TextEmbedder()  # Use the default model \"nomic-embed-text\"\n",
    "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VectorDB function if there is no need for addition or updation of PDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=embedding_function()\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating individual ID's for chunks in the format of source/page number/chunks Index. This solves the problem of having to create new database when just wanting to add content/update pdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chunk_ids(chunks):\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "    #first we gather source and page from all chunks to make a simple page/source ID\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "        #since several chunks share the same page ID, we create a condition for chunk index count\n",
    "        #this defines if the page id is same, increase the chunk index count\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        #this defines if the page is different, reset the chunk index to 0\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "        #Unique ID in desired format\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "        \n",
    "\n",
    "        # Add it to the page meta-data as an element\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "    return chunks\n",
    "#This creates the desired chunks with ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the chunks by calling the id creation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the first chunk to see if it gave us the desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk ID: data\\goog-10-k-2023 (1).pdf:0:0, Metadata: {'source': 'data\\\\goog-10-k-2023 (1).pdf', 'page': 0, 'id': 'data\\\\goog-10-k-2023 (1).pdf:0:0'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunk_to_check = chunks_with_ids[0]  \n",
    "print(f\"Chunk ID: {chunk_to_check.metadata['id']}, Metadata: {chunk_to_check.metadata}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document updation function if new PDFs are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=embedding_function\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # This is only to add or update more chunks \n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\") #length must be 0 if run first without existing DB\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "    #Runs if there are new chunks\n",
    "    if len(new_chunks):\n",
    "        print(f\"üëâ Adding new documents: {len(new_chunks)}\")\n",
    "        #create new unique IDs for new chunks\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        #Adds new chunk along with its Ids to the database\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        #for saving and future use \n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"‚úÖ No new documents to add\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argument parse for terminal handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "\n",
    "    \n",
    "    documents = load_documents()\n",
    "    chunks = split_documents(documents)\n",
    "    add_to_chroma(chunks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91979\\AppData\\Local\\Temp\\ipykernel_70724\\1219488333.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of existing documents in DB: 2098\n",
      "‚úÖ No new documents to add\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Response ---\n",
      "\n",
      " The total revenue for Google Search in 2023 is $175,033 million.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from embed_function import text_embed\n",
    "\n",
    "# Define paths and constants\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "# Prompt templates\n",
    "QUERY_PROMPT_TEMPLATE = \"\"\"\n",
    "You are an AI assistant tasked with improving the retrieval of relevant documents. \n",
    "Generate five different versions of the given user question to maximize the relevance of retrieved documents.\n",
    "Original question: {question}\n",
    "\"\"\"\n",
    "\n",
    "RAG_PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "def query_rag_with_multiquery(query_text: str):\n",
    "    # Load the Chroma vector database\n",
    "    embedding_function = text_embed()\n",
    "    vector_db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "    \n",
    "    # Initialize the LLM\n",
    "    llm = OllamaLLM(model=\"mistral-openorca\")\n",
    "    \n",
    "    query_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=QUERY_PROMPT_TEMPLATE,\n",
    "    )\n",
    "    \n",
    "    # Initialize the retriever\n",
    "    retriever = MultiQueryRetriever.from_llm(\n",
    "        vector_db.as_retriever(),\n",
    "        llm,\n",
    "        prompt=query_prompt,\n",
    "    )\n",
    "\n",
    "    # Generate the context using the retriever\n",
    "    documents = retriever.invoke(query_text)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in documents])\n",
    "\n",
    "    # Create the RAG prompt\n",
    "    rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)\n",
    "    final_prompt = rag_prompt.format(context=context_text, question=query_text)\n",
    "\n",
    "    # Invoke the LLM with the RAG prompt\n",
    "    response = llm.invoke(final_prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Test the query RAG with multiquery function directly in the notebook\n",
    "query_text = \"What is the total revenue for Google Search in 2023?\"\n",
    "\n",
    "# Call the function to get a response\n",
    "response = query_rag_with_multiquery(query_text)\n",
    "print(\"\\n--- Final Response ---\\n\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
